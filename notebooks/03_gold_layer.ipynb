{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f43d32b2-fba7-4733-97e1-30cc691e70ae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load data"
    }
   },
   "outputs": [],
   "source": [
    "#Setup and read\n",
    "from pyspark.sql.functions import (\n",
    "    col, upper, trim, current_timestamp, lit, when,\n",
    "    regexp_replace, length, coalesce, concat_ws, \n",
    "    year, datediff, to_date, count, countDistinct, sum, max, round, current_date,dense_rank,rank\n",
    ")\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN Silver\").show()\n",
    "spark.table(\"silver.customers\").printSchema()\n",
    "spark.table(\"silver.orders\").printSchema()\n",
    "spark.table(\"silver.order_items\").printSchema()\n",
    "spark.table(\"silver.products\").printSchema()\n",
    "\n",
    "print(\"====Orders====\")\n",
    "spark.table(\"silver.orders\").show(3)\n",
    "print(\"====Order Items====\")\n",
    "spark.table(\"silver.order_items\").show(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce4a1b52-1a35-42b2-a7c1-07baa4ee6ced",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Daily revenue metric"
    }
   },
   "outputs": [],
   "source": [
    "print(\"====Join====\")\n",
    "join_tables = spark.table(\"silver.orders\").join(\n",
    "    spark.table(\"silver.order_items\"), \n",
    "    \"order_id\"\n",
    ")\n",
    "\n",
    "# Crear columna de revenue\n",
    "join_with_revenue = join_tables.withColumn(\n",
    "    \"item_revenue\",\n",
    "    col(\"price\") + col(\"freight_value\")  \n",
    ")\n",
    "\n",
    "print(\"===Revenue select====\")\n",
    "join_with_revenue.select(\n",
    "    \"order_id\", \n",
    "    \"order_status\", \n",
    "    \"order_purchase_timestamp\", \n",
    "    \"price\",\n",
    "    \"freight_value\",\n",
    "    \"item_revenue\"\n",
    ").show(3)\n",
    "\n",
    "with_date_revenue = join_with_revenue.withColumn(\n",
    "    \"purchase_date\",\n",
    "    to_date(col(\"order_purchase_timestamp\"))  \n",
    ")\n",
    "\n",
    "print(\"====Date Conversion====\")\n",
    "with_date_revenue.select(\n",
    "    \"order_purchase_timestamp\", \n",
    "    \"purchase_date\"\n",
    ").show(3)\n",
    "\n",
    "print(\"===Group by Day====\")\n",
    "revenue_grouped_by_day = with_date_revenue.groupBy(\"purchase_date\").agg(\n",
    "    sum(\"item_revenue\").alias(\"total_revenue\"),\n",
    "    count(\"order_id\").alias(\"total_orders\"),\n",
    "    countDistinct(\"order_id\").alias(\"total_unique_orders\")\n",
    ").orderBy(\"purchase_date\", ascending=False)\n",
    "\n",
    "revenue_grouped_by_day.show(10)\n",
    "\n",
    "print(\"===Save====\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "\n",
    "revenue_grouped_by_day.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"gold.revenue_by_day\") \\\n",
    "    \n",
    "print(\"Table gold.revenue_by_day created sucessfully\")\n",
    "\n",
    "spark.table(\"gold.revenue_by_day\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d8c4f5-f30c-4af3-baef-921e33296a6a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Customer RFM Segment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"====Join====\")\n",
    "join_tables = spark.table(\"silver.orders\").join(\n",
    "    spark.table(\"silver.order_items\"), \n",
    "    \"order_id\"\n",
    ")\n",
    "\n",
    "# Crear columna de revenue\n",
    "join_with_revenue = join_tables.withColumn(\n",
    "    \"item_revenue\",\n",
    "    col(\"price\") + col(\"freight_value\")  \n",
    ")\n",
    "\n",
    "print(\"===Sample data select====\")\n",
    "join_with_revenue.select(\n",
    "    \"customer_id\",\n",
    "    \"order_id\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"item_revenue\"\n",
    ").show(3)\n",
    "\n",
    "\n",
    "max_date = spark.table(\"silver.orders\").agg(max(\"order_purchase_timestamp\")).collect()[0][0]\n",
    "\n",
    "\n",
    "print(\"===Group by Customer====\")\n",
    "customer_metrics = join_with_revenue.groupBy(\"customer_id\").agg(\n",
    "    \n",
    "    # RECENCY: días desde última compra\n",
    "    datediff(\n",
    "        lit(max_date), \n",
    "        max(\"order_purchase_timestamp\")\n",
    "    ).alias(\"days_since_last_order\"),\n",
    "    \n",
    "    # FREQUENCY: total de órdenes\n",
    "    countDistinct(\"order_id\").alias(\"total_orders\"),\n",
    "    \n",
    "    # MONETARY: total gastado\n",
    "    round(sum(\"item_revenue\"), 2).alias(\"total_spent\")\n",
    ")\n",
    "\n",
    "print(\"===Customer Metrics R,F,M Raw====\")\n",
    "customer_metrics.orderBy(\"total_spent\", ascending=False).show(10)\n",
    "\n",
    "print(\"Creating Scores\")\n",
    "\n",
    "print(\"===Creating Scores====\")\n",
    "customer_scored = customer_metrics.withColumn(\n",
    "    \"recency_score\",\n",
    "    when(col(\"days_since_last_order\") <= 90, 5)\n",
    "    .when(col(\"days_since_last_order\") <= 180, 4)\n",
    "    .when(col(\"days_since_last_order\") <= 365, 3)\n",
    "    .when(col(\"days_since_last_order\") <= 730, 2)\n",
    "    .otherwise(1)\n",
    ")\n",
    "\n",
    "customer_scored = customer_scored.withColumn(\n",
    "    \"frequency_score\",\n",
    "    when(col(\"total_orders\") >= 10, 5)\n",
    "    .when(col(\"total_orders\") >= 5, 4)\n",
    "    .when(col(\"total_orders\") >= 3, 3)\n",
    "    .when(col(\"total_orders\") >= 2, 2)\n",
    "    .otherwise(1)\n",
    ")\n",
    "\n",
    "customer_scored = customer_scored.withColumn(\n",
    "    \"monetary_score\",\n",
    "    when(col(\"total_spent\") >= 1000, 5)\n",
    "    .when(col(\"total_spent\") >= 500, 4)\n",
    "    .when(col(\"total_spent\") >= 200, 3)\n",
    "    .when(col(\"total_spent\") >= 100, 2)\n",
    "    .otherwise(1)\n",
    ")\n",
    "\n",
    "print(\"===Customer with Scores====\")\n",
    "customer_scored.select(\n",
    "    \"customer_id\",\n",
    "    \"days_since_last_order\", \"recency_score\",\n",
    "    \"total_orders\", \"frequency_score\",\n",
    "    \"total_spent\", \"monetary_score\"\n",
    ").show(10)\n",
    "\n",
    "print(\"Creating Segments\")\n",
    "customer_rfm_segments = customer_scored.withColumn(\n",
    "    \"segment\",\n",
    "    when(\n",
    "        (col(\"recency_score\") >= 4) & \n",
    "        (col(\"frequency_score\") >= 4) & \n",
    "        (col(\"monetary_score\") >= 4),\n",
    "        \"Champions\"\n",
    "    )\n",
    "    .when(col(\"frequency_score\") >= 4, \"Loyal Customers\")\n",
    "    .when(\n",
    "        (col(\"recency_score\") >= 4) & \n",
    "        (col(\"frequency_score\") >= 2),\n",
    "        \"Potential Loyalist\"\n",
    "    )\n",
    "    .when(\n",
    "        (col(\"recency_score\") <= 2) & \n",
    "        (col(\"frequency_score\") >= 3),\n",
    "        \"At Risk\"\n",
    "    )\n",
    "    .when(\n",
    "        (col(\"recency_score\") <= 2) & \n",
    "        (col(\"frequency_score\") <= 2),\n",
    "        \"Hibernating\"\n",
    "    )\n",
    "    .when(\n",
    "        (col(\"recency_score\") >= 4) & \n",
    "        (col(\"frequency_score\") == 1),\n",
    "        \"New Customers\"\n",
    "    )\n",
    "    .otherwise(\"Need Attention\")\n",
    ")\n",
    "\n",
    "print(\"===Segment Distribution====\")\n",
    "customer_rfm_segments.groupBy(\"segment\").agg(\n",
    "    count(\"customer_id\").alias(\"customer_count\"),\n",
    "    round(sum(\"total_spent\"), 2).alias(\"segment_revenue\")\n",
    ").orderBy(\"segment_revenue\", ascending=False).show()\n",
    "\n",
    "\n",
    "print(\"===Save====\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS gold.customer_rfm_segments\")\n",
    "\n",
    "# Now write your DataFrame as a new Delta table\n",
    "customer_rfm_segments.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"gold.customer_rfm_segments\")\n",
    "\n",
    "print(\"Table gold.RFM_Analysis created sucessfully\")\n",
    "\n",
    "spark.table(\"gold.customer_rfm_segments\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70365c0b-388c-44d4-ab47-a9508c35d08a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Product Performance"
    }
   },
   "outputs": [],
   "source": [
    "df_orders = spark.table(\"silver.orders\")\n",
    "df_order_items = spark.table(\"silver.order_items\")\n",
    "df_products = spark.table(\"silver.products\")\n",
    "\n",
    "spark.table(\"silver.products\").printSchema\n",
    "\n",
    "df_product_revenue = (df_order_items\n",
    "                      .join(df_products, on=\"product_id\", how=\"left\")\n",
    "                      .join(df_orders.select(\"order_id\", \"order_status\"), on=\"order_id\", how=\"left\")\n",
    "                      .groupBy(\"product_id\", \"product_category_name\")\n",
    "                      .agg(\n",
    "                          sum(col(\"price\") + col(\"freight_value\")).alias(\"item_revenue\"),\n",
    "                          count(\"order_id\").alias(\"total_orders\"),\n",
    "                          round(sum(col(\"price\") + col(\"freight_value\")) / count(\"order_id\"), 2).alias(\"avg_order_value\")\n",
    "                      )\n",
    ")\n",
    "\n",
    "\n",
    "window_spec = Window.orderBy(col(\"item_revenue\").desc())\n",
    "\n",
    "df_ranked = (df_product_revenue\n",
    "             .withColumn(\"revenue_rank\", dense_rank().over(window_spec))\n",
    "             .withColumn(\"data_source\", lit(\"olist\"))\n",
    "             .withColumn(\"data_layer\", lit(\"gold\"))\n",
    "             .withColumn(\"processed_at\", current_timestamp())\n",
    "             .orderBy(\"revenue_rank\")\n",
    ")            \n",
    "\n",
    "print(f\"Analysis complete: {df_ranked.count()} products ranked\")\n",
    "\n",
    "df_category_summary = (df_product_revenue\n",
    "                       .groupBy(\"product_category_name\")\n",
    "                       .agg(\n",
    "                           sum(col(\"item_revenue\")).alias(\"category_total_revenue\"),\n",
    "                           sum(col(\"total_orders\")).alias(\"category_total_orders\"),\n",
    "                           count(\"product_id\").alias(\"products_in_category\")\n",
    "                       )\n",
    "                       .orderBy(col(\"category_total_revenue\").desc())\n",
    ")\n",
    "\n",
    "print(\"Product Perfomance complete by Category\")\n",
    "print(f\"Top Product Revenue: R${df_ranked.select('item_revenue').first()[0]:,.2f}\")\n",
    "print(f\"Top category: {df_category_summary.select('product_category_name').first()[0]}\")\n",
    "\n",
    "\n",
    "print(\"===Save====\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "\n",
    "df_category_summary.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"gold.product_category_summary\") \\\n",
    "    \n",
    "print(\"Table gold.product_category_summary created sucessfully\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_gold_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
