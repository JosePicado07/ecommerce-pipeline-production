{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c65ea932-a983-4739-964f-296b2e231738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install great-expectations==0.18.12\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6d3ee8a-6dae-4ddc-8286-16be29a83423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, min, max\n",
    "import great_expectations as ge\n",
    "from great_expectations.dataset import SparkDFDataset\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Great Expectations version: {ge.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fbbf4b0-6cce-4ee5-bd0b-0cfec323ea1a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Revenue by Day Validation"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, min, max, when, count\n",
    "from datetime import datetime\n",
    "\n",
    "# Validación para revenue_by_day\n",
    "print(\"Validating: gold.revenue_by_day\")\n",
    "df_revenue = spark.table(\"gold.revenue_by_day\")\n",
    "\n",
    "total_rows = df_revenue.count()\n",
    "print(f\"Total rows in table: {total_rows}\")\n",
    "\n",
    "null_checks = {}\n",
    "for col_name in [\"purchase_date\",\"total_revenue\",\"total_orders\",\"total_unique_orders\"]:\n",
    "    null_count = df_revenue.filter(col(col_name).isNull()).count()\n",
    "    null_checks[col_name] = null_count\n",
    "    status = \"passed\" if null_count == 0 else \"failed\"\n",
    "    print(f\"Null check for column {col_name}: {status} - {null_count} nulls found\")\n",
    "\n",
    "negative_revenue = df_revenue.filter(col(\"total_revenue\") < 0).count()\n",
    "status = \"passed\" if negative_revenue == 0 else \"failed\"\n",
    "print(f\"Revenue validation (>= 0): {status} - {negative_revenue} invalid records\")\n",
    "\n",
    "invalid_logic = df_revenue.filter(col(\"total_orders\") < col(\"total_unique_orders\")).count()\n",
    "status = \"passed\" if invalid_logic == 0 else \"failed\"\n",
    "print(f\"Business logic (orders >= customers): {status} - {invalid_logic} invalid records\")\n",
    "\n",
    "date_stats = df_revenue.select(\n",
    "    min(\"purchase_date\").alias(\"min_date\"),\n",
    "    max(\"purchase_date\").alias(\"max_date\")\n",
    ").collect()[0]\n",
    "print(f\"Date range validation: passed - {date_stats['min_date']} to {date_stats['max_date']}\")\n",
    "\n",
    "checks_passed = sum([v == 0 for v in null_checks.values()]) + int(negative_revenue == 0) + int(invalid_logic == 0)\n",
    "total_checks = len(null_checks) + 2\n",
    "success_rate = (checks_passed / total_checks) * 100\n",
    "print(f\"\\nSummary: {checks_passed}/{total_checks} checks passed ({success_rate:.0f}%)\")\n",
    "\n",
    "revenue_checks = (checks_passed, total_checks)\n",
    "\n",
    "# Validación para customer_rfm_segments\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validating: gold.customer_rfm_segments\")\n",
    "\n",
    "df_rfm = spark.table(\"gold.customer_rfm_segments\")\n",
    "\n",
    "total_rows = df_rfm.count()\n",
    "print(f\"Total rows in table: {total_rows}\")\n",
    "\n",
    "# Primero verificar qué columnas existen realmente\n",
    "available_cols = df_rfm.columns\n",
    "print(f\"Available columns: {available_cols}\")\n",
    "\n",
    "# Solo validar columnas que existen\n",
    "rfm_columns_to_check = [\"customer_id\", \"segment\", \"total_spent\", \"total_orders\", \n",
    "                       \"recency_score\", \"frequency_score\", \"monetary_score\", \"days_since_last_order\"]\n",
    "existing_cols = [col for col in rfm_columns_to_check if col in df_rfm.columns]\n",
    "\n",
    "print(f\"Validating columns: {existing_cols}\")\n",
    "\n",
    "null_checks = {}\n",
    "for col_name in existing_cols:\n",
    "    null_count = df_rfm.filter(col(col_name).isNull()).count()\n",
    "    null_checks[col_name] = null_count\n",
    "    status = \"passed\" if null_count == 0 else \"failed\"\n",
    "    print(f\"Null check for column {col_name}: {status} - {null_count} nulls found\")\n",
    "\n",
    "# CHECK 2: Customer_id uniqueness (solo si existe)\n",
    "if \"customer_id\" in df_rfm.columns:\n",
    "    duplicate_customers = df_rfm.groupBy(\"customer_id\").count().filter(col(\"count\") > 1).count()\n",
    "    status = \"passed\" if duplicate_customers == 0 else \"failed\"\n",
    "    print(f\"Uniqueness check (customer_id): {status} - {duplicate_customers} duplicates found\")\n",
    "else:\n",
    "    duplicate_customers = 0\n",
    "    print(\"Uniqueness check (customer_id): skipped - column not found\")\n",
    "\n",
    "# CHECK 3: RFM scores in range [1-5] (solo si existen)\n",
    "score_checks = {}\n",
    "for score_col in [\"recency_score\", \"frequency_score\", \"monetary_score\"]:\n",
    "    if score_col in df_rfm.columns:\n",
    "        invalid_scores = df_rfm.filter((col(score_col) < 1) | (col(score_col) > 5)).count()\n",
    "        score_checks[score_col] = invalid_scores\n",
    "        status = \"passed\" if invalid_scores == 0 else \"failed\"\n",
    "        print(f\"Range validation {score_col} [1-5]: {status} - {invalid_scores} invalid records\")\n",
    "    else:\n",
    "        score_checks[score_col] = 0\n",
    "        print(f\"Range validation {score_col} [1-5]: skipped - column not found\")\n",
    "\n",
    "# CHECK 4: Recency >= 0 (solo si existe)\n",
    "if \"days_since_last_order\" in df_rfm.columns:\n",
    "    negative_recency = df_rfm.filter(col(\"days_since_last_order\") < 0).count()\n",
    "    status = \"passed\" if negative_recency == 0 else \"failed\"\n",
    "    print(f\"Recency validation (>= 0): {status} - {negative_recency} invalid records\")\n",
    "else:\n",
    "    negative_recency = 0\n",
    "    print(\"Recency validation (>= 0): skipped - column not found\")\n",
    "\n",
    "# CHECK 5: Frequency >= 1 (solo si existe)\n",
    "if \"total_orders\" in df_rfm.columns:\n",
    "    zero_frequency = df_rfm.filter(col(\"total_orders\") < 1).count()\n",
    "    status = \"passed\" if zero_frequency == 0 else \"failed\"\n",
    "    print(f\"Frequency validation (>= 1): {status} - {zero_frequency} invalid records\")\n",
    "else:\n",
    "    zero_frequency = 0\n",
    "    print(\"Frequency validation (>= 1): skipped - column not found\")\n",
    "\n",
    "# CHECK 6: Monetary > 0 (solo si existe)\n",
    "if \"total_spent\" in df_rfm.columns:\n",
    "    zero_monetary = df_rfm.filter(col(\"total_spent\") <= 0).count()\n",
    "    status = \"passed\" if zero_monetary == 0 else \"failed\"\n",
    "    print(f\"Monetary validation (> 0): {status} - {zero_monetary} invalid records\")\n",
    "else:\n",
    "    zero_monetary = 0\n",
    "    print(\"Monetary validation (> 0): skipped - column not found\")\n",
    "\n",
    "# CHECK 7: Valid segments (solo si existe)\n",
    "if \"segment\" in df_rfm.columns:\n",
    "    valid_segments = [\n",
    "        \"Champions\", \"Loyal Customers\", \"Potential Loyalist\",\n",
    "        \"New Customers\", \"Promising\", \"Need Attention\",\n",
    "        \"About to Sleep\", \"At Risk\", \"Can't Lose Them\",\n",
    "        \"Hibernating\", \"Lost\"\n",
    "    ]\n",
    "    invalid_segments = df_rfm.filter(~col(\"segment\").isin(valid_segments)).count()\n",
    "    status = \"passed\" if invalid_segments == 0 else \"failed\"\n",
    "    print(f\"Segment validation (valid values): {status} - {invalid_segments} invalid records\")\n",
    "else:\n",
    "    invalid_segments = 0\n",
    "    print(\"Segment validation (valid values): skipped - column not found\")\n",
    "\n",
    "# Summary\n",
    "rfm_checks_passed = (\n",
    "    sum([v == 0 for v in null_checks.values()]) +\n",
    "    (duplicate_customers == 0) +\n",
    "    sum([v == 0 for v in score_checks.values()]) +\n",
    "    (negative_recency == 0) +\n",
    "    (zero_frequency == 0) +\n",
    "    (zero_monetary == 0) +\n",
    "    (invalid_segments == 0)\n",
    ")\n",
    "\n",
    "rfm_total_checks = (\n",
    "    len(null_checks) + \n",
    "    1 +  # uniqueness check\n",
    "    len(score_checks) + \n",
    "    4    # recency, frequency, monetary, segment checks\n",
    ")\n",
    "\n",
    "rfm_success_rate = (rfm_checks_passed / rfm_total_checks) * 100\n",
    "print(f\"\\nSummary: {rfm_checks_passed}/{rfm_total_checks} checks passed ({rfm_success_rate:.0f}%)\")\n",
    "\n",
    "rfm_checks = (rfm_checks_passed, rfm_total_checks)\n",
    "\n",
    "# Validación para product_performance_ranking\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validating: gold.product_category_summary\")\n",
    "\n",
    "df_products = spark.table(\"gold.product_category_summary\")\n",
    "\n",
    "total_rows = df_products.count()\n",
    "print(f\"Total rows in table: {total_rows}\")\n",
    "\n",
    "# Verificar columnas disponibles\n",
    "available_cols = df_products.columns\n",
    "print(f\"Available columns: {available_cols}\")\n",
    "\n",
    "# Columnas específicas para productos\n",
    "product_columns_to_check = [\"product_id\", \"item_revenue\", \"total_orders\", \"revenue_rank\", \"avg_order_value\"]\n",
    "existing_prod_cols = [col for col in product_columns_to_check if col in df_products.columns]\n",
    "\n",
    "print(f\"Validating columns: {existing_prod_cols}\")\n",
    "\n",
    "null_checks = {}\n",
    "for col_name in existing_prod_cols:\n",
    "    null_count = df_products.filter(col(col_name).isNull()).count()\n",
    "    null_checks[col_name] = null_count\n",
    "    status = \"passed\" if null_count == 0 else \"failed\"\n",
    "    print(f\"Null check for column {col_name}: {status} - {null_count} nulls found\")\n",
    "\n",
    "# CHECK 2: Product_id uniqueness\n",
    "if \"product_id\" in df_products.columns:\n",
    "    duplicate_products = df_products.groupBy(\"product_id\").count().filter(col(\"count\") > 1).count()\n",
    "    status = \"passed\" if duplicate_products == 0 else \"failed\"\n",
    "    print(f\"Uniqueness check (product_id): {status} - {duplicate_products} duplicates found\")\n",
    "else:\n",
    "    duplicate_products = 0\n",
    "    print(\"Uniqueness check (product_id): skipped - column not found\")\n",
    "\n",
    "# CHECK 3: Revenue > 0\n",
    "if \"item_revenue\" in df_products.columns:\n",
    "    zero_revenue = df_products.filter(col(\"item_revenue\") <= 0).count()\n",
    "    status = \"passed\" if zero_revenue == 0 else \"failed\"\n",
    "    print(f\"Revenue validation (> 0): {status} - {zero_revenue} invalid records\")\n",
    "else:\n",
    "    zero_revenue = 0\n",
    "    print(\"Revenue validation (> 0): skipped - column not found\")\n",
    "\n",
    "# CHECK 4: Orders >= 1\n",
    "if \"total_orders\" in df_products.columns:\n",
    "    zero_orders = df_products.filter(col(\"total_orders\") < 1).count()\n",
    "    status = \"passed\" if zero_orders == 0 else \"failed\"\n",
    "    print(f\"Orders validation (>= 1): {status} - {zero_orders} invalid records\")\n",
    "else:\n",
    "    zero_orders = 0\n",
    "    print(\"Orders validation (>= 1): skipped - column not found\")\n",
    "\n",
    "# CHECK 5: Ranking >= 1\n",
    "if \"revenue_rank\" in df_products.columns:\n",
    "    invalid_rank = df_products.filter(col(\"revenue_rank\") < 1).count()\n",
    "    status = \"passed\" if invalid_rank == 0 else \"failed\"\n",
    "    print(f\"Ranking validation (>= 1): {status} - {invalid_rank} invalid records\")\n",
    "else:\n",
    "    invalid_rank = 0\n",
    "    print(\"Ranking validation (>= 1): skipped - column not found\")\n",
    "\n",
    "# CHECK 6: AOV consistency\n",
    "if \"avg_order_value\" in df_products.columns and \"item_revenue\" in df_products.columns and \"total_orders\" in df_products.columns:\n",
    "    df_aov_check = df_products.withColumn(\n",
    "        \"aov_calculated\", \n",
    "        col(\"item_revenue\") / col(\"total_orders\")\n",
    "    ).withColumn(\n",
    "        \"aov_diff\",\n",
    "        when(col(\"avg_order_value\").isNotNull(), \n",
    "             col(\"avg_order_value\") - col(\"aov_calculated\")\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "    aov_inconsistent = df_aov_check.filter(\n",
    "        (col(\"aov_diff\") > 0.01) | (col(\"aov_diff\") < -0.01)\n",
    "    ).count()\n",
    "    status = \"passed\" if aov_inconsistent == 0 else \"failed\"\n",
    "    print(f\"AOV consistency validation: {status} - {aov_inconsistent} inconsistent records\")\n",
    "else:\n",
    "    aov_inconsistent = 0\n",
    "    print(\"AOV consistency validation: skipped - required columns not found\")\n",
    "\n",
    "# Summary\n",
    "prod_checks_passed = (\n",
    "    sum([v == 0 for v in null_checks.values()]) +\n",
    "    (duplicate_products == 0) +\n",
    "    (zero_revenue == 0) +\n",
    "    (zero_orders == 0) +\n",
    "    (invalid_rank == 0) +\n",
    "    (aov_inconsistent == 0)\n",
    ")\n",
    "\n",
    "prod_total_checks = len(null_checks) + 5\n",
    "prod_success_rate = (prod_checks_passed / prod_total_checks) * 100\n",
    "print(f\"\\nSummary: {prod_checks_passed}/{prod_total_checks} checks passed ({prod_success_rate:.0f}%)\")\n",
    "\n",
    "prod_checks = (prod_checks_passed, prod_total_checks)\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_checks_all = revenue_checks[1] + rfm_checks[1] + prod_checks[1]\n",
    "total_passed_all = revenue_checks[0] + rfm_checks[0] + prod_checks[0]\n",
    "overall_success = (total_passed_all / total_checks_all) * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "Total validations executed: {total_checks_all}\n",
    "Validations passed: {total_passed_all}\n",
    "Validations failed: {total_checks_all - total_passed_all}\n",
    "Overall success rate: {overall_success:.1f}%\n",
    "\n",
    "Breakdown by table:\n",
    "  - revenue_by_day: {success_rate:.0f}% ({revenue_checks[0]}/{revenue_checks[1]})\n",
    "  - customer_rfm_segments: {rfm_success_rate:.0f}% ({rfm_checks[0]}/{rfm_checks[1]})\n",
    "  - product_performance_ranking: {prod_success_rate:.0f}% ({prod_checks[0]}/{prod_checks[1]})\n",
    "\n",
    "Validation timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\")\n",
    "\n",
    "if overall_success >= 95:\n",
    "    print(\"Status: ✅ EXCELLENT - High data quality\")\n",
    "elif overall_success >= 80:\n",
    "    print(\"Status: ✅ GOOD - Acceptable data quality\")\n",
    "else:\n",
    "    print(\"Status: ⚠️ NEEDS ATTENTION - Review failures\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_data_quality_checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
